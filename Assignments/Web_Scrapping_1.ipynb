{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d450e2-b6c4-4caf-a907-64d94c749cfe",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4bef4-2c06-4519-b3d3-1e7feb9d2353",
   "metadata": {},
   "source": [
    "Web scraping, also known as data scraping, is the automated extraction of data from websites. It involves using software tools to extract information from the HTML or other structured web page formats and then storing that information in a structured format, such as a database or a spreadsheet.\n",
    "\n",
    "Web scraping is used for:\n",
    "1. Data collection: Companies and individuals may use web scraping to collect data from various sources, such as social media, online marketplaces, and e-commerce websites.\n",
    "\n",
    "2. Research: Researchers may use web scraping to gather data for academic or commercial research purposes, such as analyzing social media trends or monitoring competitor pricing strategies.\n",
    "\n",
    "3. Monitoring: Web scraping can be used to monitor websites for changes in content, prices, or other information of interest. This can be useful for tracking market trends, detecting fraud, or staying up-to-date on news and events.\n",
    "\n",
    "Three areas where web scraping is used to gather data include:\n",
    "\n",
    "1. E-commerce: Web scraping is often used to gather pricing data from e-commerce websites, which can be used to inform pricing strategies or to monitor competitors.\n",
    "\n",
    "2. Social media: Web scraping is used to gather data from social media platforms, such as Twitter or Facebook, to monitor sentiment, track trending topics, or analyze user behavior.\n",
    "\n",
    "3. Market research: Web scraping is used to gather data from a variety of sources to inform market research efforts, such as analyzing customer reviews or monitoring competitor websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4bc7a-8f57-45b8-931c-ec6e54a23784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f601a245-547f-4dbb-b78c-fdf8623c6508",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be140e0-5c55-4fa2-9d19-f261c9385fde",
   "metadata": {},
   "source": [
    "There are several methods that can be used for web scraping. Some common methods include:\n",
    "\n",
    "1. Manual Scraping: This method involves manually copying and pasting data from websites into a spreadsheet or database. It is a time-consuming and tedious process but may be appropriate for small-scale scraping projects.\n",
    "\n",
    "2. Web Scraping Software: This method involves using software tools to automate the data extraction process. These tools can be customized to scrape specific data from websites and can be more efficient than manual scraping.\n",
    "\n",
    "3. Application Programming Interfaces (APIs): Some websites offer APIs that allow developers to access their data in a structured format. This method can be more reliable and efficient than web scraping because the data is provided directly by the website.\n",
    "\n",
    "4. Parsing HTML: This method involves parsing the HTML code of a web page to extract data. It requires knowledge of HTML and can be more complex than other methods.\n",
    "\n",
    "5. Headless Browsing: This method involves using a web browser to navigate and scrape websites, but without displaying the actual browser interface. It can be more effective than parsing HTML because it can handle dynamic content and JavaScript-driven web pages.\n",
    "\n",
    "5. Crawling: This method involves systematically visiting and scraping data from multiple pages on a website. It can be useful for scraping large amounts of data, but may also be more complex and require more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97a8d3-c48f-49d6-9608-c86d35582c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbdfa341-0dd3-4ba9-b5fb-943a8d248be8",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb67023-2caa-43b9-8114-7f676b02131f",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for web scraping purposes. It is designed to make parsing HTML and XML documents easy and efficient. Beautiful Soup provides a set of functions and methods that allow developers to extract data from HTML or XML files, navigate the parsed tree structure of the document, and search for specific tags, attributes, or text content. It is commonly used for web scraping because it can handle poorly formatted HTML code and dynamically generated web pages, which can be difficult for other parsing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd473d10-2862-4eb1-b46f-e742567463bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89e9e216-1d0c-4273-816a-8da97486d603",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a5795-20a9-422e-a0f7-69ed115f35f7",
   "metadata": {},
   "source": [
    "Flask is used to create API and also, create a web page to get input. It is later used to write code for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886bc2d-3f31-4f98-9151-afb7c2996ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eef2688d-2882-49b4-90a7-515a1523eb61",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c9e65-b78c-4c4a-b683-aece4c996687",
   "metadata": {},
   "source": [
    "AWS Elastic Beanstalk and AWS CodePipeline are used in this project.\n",
    "\n",
    "AWS Elastic Beanstalk provides you with resources needed to create application.\n",
    "\n",
    "AWS CodePipeline is used to get code and create a connection between github and aws elastic beanstalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8f3ee-794e-4a7d-b881-d9745128504b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
